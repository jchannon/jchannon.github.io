<rss xmlns:a10="http://www.w3.org/2005/Atom" version="2.0"><channel><title>Jonathan Channon Blog</title><link>http://blog.jonathanchannon.com/feed.xml</link><description>Jonathan Channon Blog</description><item><guid isPermaLink="true">http://blog.jonathanchannon.com/2014/01/02/unit-testing-with-sqlexception/</guid><link>http://blog.jonathanchannon.com/2014/01/02/unit-testing-with-sqlexception/</link><title>Unit Testing with SqlException</title><description>&lt;p&gt;So after a nice Christmas break I get to some code that needs some unit testing around a try/catch. Something similar to this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;try
{
    myService.DoSomethingThatMightTakeALongTime();
}
catch (EntityCommandExecutionException ex)
{
    var exception = ex.InnerException as SqlException;
    if (exception != null)
    {
        if (exception.Number == -2)
        {
            //Do something special
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

</description><pubDate>Thu, 02 Jan 2014 00:00:00 Z</pubDate><a10:updated>2014-01-02T00:00:00Z</a10:updated><a10:content type="text">&lt;p&gt;So after a nice Christmas break I get to some code that needs some unit testing around a try/catch. Something similar to this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;try
{
    myService.DoSomethingThatMightTakeALongTime();
}
catch (EntityCommandExecutionException ex)
{
    var exception = ex.InnerException as SqlException;
    if (exception != null)
    {
        if (exception.Number == -2)
        {
            //Do something special
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;!--excerpt--&gt;

&lt;p&gt;Obviously &lt;code&gt;myService&lt;/code&gt; has a interface that can be mocked and I can tell it to throw a &lt;code&gt;EntityCommandExecutionException&lt;/code&gt; when &lt;code&gt;DoSomethingThatMightTakeALongTime&lt;/code&gt; is called and the constructor for that takes a string and an Exception as an inner exception.  However, you can't create a new instance of SqlException because its a sealed class therefore doing the below is impossible:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var fakeService = A.Fake&amp;lt;IMyService&amp;gt;();
A.CallTo(() =&amp;gt; fakeService.DoSomethingThatMightTakeALongTime()).Throws(new EntityCommandExecutionException("What a mistaka da maka", new SqlException());
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can't create your own exception class and inherit off SqlException to get around it that way either.  You could use &lt;code&gt;System.Runtime.Serialization.FormatterServices.GetUninitializedObject&lt;/code&gt; to give you a &lt;code&gt;SqlException&lt;/code&gt; but that won't have the &lt;code&gt;Number&lt;/code&gt; property assigned to -2.  You could also setup a method in your test class that tries to connect to a non existant db that times out after 1 second but again that won't give you the Number property you may want plus its a lot of ugly and unnecessary code in a unit test project.  &lt;/p&gt;

&lt;h2&gt;How did you do it?&lt;/h2&gt;

&lt;p&gt;So after browsing all the stackoverflow answers and comments I came up with a solution that worked which I thought I'd share so here it is:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;private SqlException GetSqlException()
{
    SqlErrorCollection collection = Construct&amp;lt;SqlErrorCollection&amp;gt;();
    SqlError error = Construct&amp;lt;SqlError&amp;gt;(-2, (byte)2, (byte)3, "server name", "error message", "proc", 100, (uint)1);

    typeof(SqlErrorCollection)
        .GetMethod("Add", BindingFlags.NonPublic | BindingFlags.Instance)
        .Invoke(collection, new object[] { error });    

    var e = typeof(SqlException)
        .GetMethod("CreateException", BindingFlags.NonPublic | BindingFlags.Static, null, CallingConventions.ExplicitThis, new[] { typeof(SqlErrorCollection), typeof(string) }, new ParameterModifier[] { })
        .Invoke(null, new object[] { collection, "11.0.0" }) as SqlException;

    return e;
}

private T Construct&amp;lt;T&amp;gt;(params object[] p)
{
    return (T)typeof(T).GetConstructors(BindingFlags.NonPublic | BindingFlags.Instance)[0].Invoke(p);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can then amend the previous mocking code to look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var fakeService = A.Fake&amp;lt;IMyService&amp;gt;();
A.CallTo(() =&amp;gt; fakeService.DoSomethingThatMightTakeALongTime()).Throws(new EntityCommandExecutionException("What a mistaka da maka", GetSqlException());
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As you can see it uses reflection to create instances of all the sealed classes required and it also calls sealed methods to assign properties ie/adding the error instance to the collection instance.  You'll see that the -2 value is the first argument in the parameters used to construct the SqlError object so if you're interested in using the Number property on the exception thats where to change it.&lt;/p&gt;

&lt;h2&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;This approach works and allows me to test my code but all in all its not particualry elegant and the following gif can sum up what we've learnt from sealed methods and classes and thats they're &lt;em&gt;nasty&lt;/em&gt;: &lt;/p&gt;

&lt;p&gt;&lt;img src="http://i.imgur.com/pR3tklc.gif" alt="Nasty" /&gt;&lt;/p&gt;
</a10:content></item><item><guid isPermaLink="true">http://blog.jonathanchannon.com/2013/12/20/using-sql-server-with-nodejs/</guid><link>http://blog.jonathanchannon.com/2013/12/20/using-sql-server-with-nodejs/</link><title>Using SQL Server with node.js</title><description>&lt;p&gt;I like to keep eyes and ears open for new technologies and methodologies in order to become a better developer and I'd heard about &lt;a href="http://tjanczuk.github.io/edge/#/"&gt;edge.js&lt;/a&gt; many months ago but made a mental note of it and waved it goodbye.  edge.js lets you have two-way communication between node and C# libraries.  When I first looked at it I thought that sounded a bit hacky, I've spent my time communicating with COM libraries in Delphi and OCX libraries with C# and didn't like it so I felt this was pretty much the same thing.  A long time passed and I was writing a console based Windows app as a service and had wondererd whether I could quickly port it to node.  &lt;/p&gt;

&lt;p&gt;I was discussing with a colleague about using node at work and that we needed something seperate and small just to try it out and see how the whole developement process with it worked.  As the database that this app needed to communicate with was MSSQL I looked into a library on NPM that would communicate with MSSQL and maybe act as an ORM.  There was a Microsoft lib that seemed untouched and reading the comments on the issues list on Github it didnt favour too well.  There were libraries that would communicate with MySQL &amp;amp; PostgresSQL but not MSSQL.  In my search I came across edge.js again.  It had 2 samples, one that used edge-sql and one that used ScriptCS so in laymans terms, one that used a precompiled dll and one that used a C# script that was executed at runtime.&lt;/p&gt;

</description><pubDate>Fri, 20 Dec 2013 00:00:00 Z</pubDate><a10:updated>2013-12-20T00:00:00Z</a10:updated><a10:content type="text">&lt;p&gt;I like to keep eyes and ears open for new technologies and methodologies in order to become a better developer and I'd heard about &lt;a href="http://tjanczuk.github.io/edge/#/"&gt;edge.js&lt;/a&gt; many months ago but made a mental note of it and waved it goodbye.  edge.js lets you have two-way communication between node and C# libraries.  When I first looked at it I thought that sounded a bit hacky, I've spent my time communicating with COM libraries in Delphi and OCX libraries with C# and didn't like it so I felt this was pretty much the same thing.  A long time passed and I was writing a console based Windows app as a service and had wondererd whether I could quickly port it to node.  &lt;/p&gt;

&lt;p&gt;I was discussing with a colleague about using node at work and that we needed something seperate and small just to try it out and see how the whole developement process with it worked.  As the database that this app needed to communicate with was MSSQL I looked into a library on NPM that would communicate with MSSQL and maybe act as an ORM.  There was a Microsoft lib that seemed untouched and reading the comments on the issues list on Github it didnt favour too well.  There were libraries that would communicate with MySQL &amp;amp; PostgresSQL but not MSSQL.  In my search I came across edge.js again.  It had 2 samples, one that used edge-sql and one that used ScriptCS so in laymans terms, one that used a precompiled dll and one that used a C# script that was executed at runtime.&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;p&gt;Looking at the samples the Github repo gave you could do the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var edge = require('edge');

var getTop10Products = edge.func('sql', function () {/*
    select top 10 * from Products
*/});

getTop10Products(null, function (error, result) {
    if (error) throw error;
    console.log(result);
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Thats it, you could call &lt;code&gt;node myscript&lt;/code&gt; and it would log out the values of the result variable.  &lt;/p&gt;

&lt;p&gt;What this did was in fact send the SQL string to a compiled dll which had a class and async method in it that was setup to respond to calls from node js.  This method essentially returned a C# &lt;code&gt;List&amp;lt;object&amp;gt;&lt;/code&gt; that was serialized to JSON so the node.js function could interact with it.  The one issue I saw with it was the actual format of the JSON.  It was a 2 dimentional array, with the first array in the parent array containing the column names and the subsequent arrays containing values from the rows in the SQL result.  &lt;/p&gt;

&lt;h2&gt;Time to roll up your sleeves&lt;/h2&gt;

&lt;p&gt;Whilst I liked the fact that I could now return data from MSSQL with node its format wasnt quite right.  I forked the project on Github and then looked at the way it was executing the SQL and storing it in a &lt;code&gt;List&amp;lt;object&amp;gt;&lt;/code&gt;.  Whilst I kept the &lt;code&gt;List&amp;lt;object&amp;gt;&lt;/code&gt; return type the information inside it differed.  I was now using &lt;code&gt;var dataObject = new ExpandoObject() as IDictionary&amp;lt;string, Object&amp;gt;;&lt;/code&gt; and for each field in the resulting SQL dataset I populated it like so &lt;code&gt;dataObject.Add(record.GetName(i), resultRecord[i]);&lt;/code&gt; ie/ the column name and corresponding value.  So this looped over the sql storing objects in a list and then returning it as JSON as it did before.  What this meant was that the API had now changed so I could refer to the column names as object properties on the node object.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;getTop10Products(null, function (error, result) {
    if (error) throw error;
    console.log(result[0].ProductName);
    console.log(result[1].UnitPrice);
});
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Bingo!&lt;/p&gt;

&lt;p&gt;So now just out of curisotiy I wanted to right a sample ExpressJS app to see how I could use this to have a JS file that acted as a C# repository to do all the data access.  I'll let you look into setting express up yourself but what I managed to do was this:&lt;/p&gt;

&lt;h4&gt;server.js&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;var express = require('express');
var edge = require('edge');
var index = require('./index.js');
var db = require('./db.js');

var app = express();

app.get('/', index.home(db));

app.listen(999);
console.log('Listening on port 999')
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;db.js&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;var edge = require('edge');

exports.getProducts = edge.func('sql', function() {/*
                    select top 10 * from Products 
                 */});
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;index.js&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;exports.home = function(db) {
    return function(req, res) {
        db.getProducts(null, function(error, result) {
            if (error) throw error;
            var data = {};
            data.all = result;
            data.Item1Name = result[0].ProductName;
            data.Item2ReorderLevel = result[1].ReorderLevel;
            res.send(data);
        });
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I fired up a browser and pointed it at http://localhost:999 and it returned showed me my 10 products, then my first item's product name and second item's re-order level. Consider me pleased!&lt;/p&gt;

&lt;h2&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;I know some people will think using MSSQL for a node app seems odd but if you want to spike something up and/or only have access to a MSSQL db for whatever reason you can now do it very easily and actually quite elegantly.  You execute your SQL and you get back a JSON object that represents your data, same as any other SQL/NOSQL database.  Give it a whirl and see how you get on!&lt;/p&gt;
</a10:content></item><item><guid isPermaLink="true">http://blog.jonathanchannon.com/2013/11/25/octopus-xml-transformation-in-services/</guid><link>http://blog.jonathanchannon.com/2013/11/25/octopus-xml-transformation-in-services/</link><title>Octopus XML Transformation in Services</title><description>&lt;p&gt;We use &lt;a href="http://octopusdeploy.com/"&gt;Octopus Deploy&lt;/a&gt; at work and its a superb tool for deploying your applications whether they be websites or *.exes.&lt;/p&gt;

&lt;p&gt;One of the great things it also provides is the ability to use &lt;a href="http://msdn.microsoft.com/en-us/library/dd465326.aspx"&gt;Microsoft's Transformation&lt;/a&gt; process for config files.  However, when deploying a exe application its a bit trickier than a website.  Unfortunately the documentation doesn't mention the steps needed to get this working so read on!  &lt;/p&gt;

&lt;p&gt;Typically a web application will have web.config and a web.Release.config as well as other derivations you may use.  Octopus also supports web.[Environment].config.&lt;/p&gt;

</description><pubDate>Mon, 25 Nov 2013 00:00:00 Z</pubDate><a10:updated>2013-11-25T00:00:00Z</a10:updated><a10:content type="text">&lt;p&gt;We use &lt;a href="http://octopusdeploy.com/"&gt;Octopus Deploy&lt;/a&gt; at work and its a superb tool for deploying your applications whether they be websites or *.exes.&lt;/p&gt;

&lt;p&gt;One of the great things it also provides is the ability to use &lt;a href="http://msdn.microsoft.com/en-us/library/dd465326.aspx"&gt;Microsoft's Transformation&lt;/a&gt; process for config files.  However, when deploying a exe application its a bit trickier than a website.  Unfortunately the documentation doesn't mention the steps needed to get this working so read on!  &lt;/p&gt;

&lt;p&gt;Typically a web application will have web.config and a web.Release.config as well as other derivations you may use.  Octopus also supports web.[Environment].config.&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;p&gt;In a console application you have an app.config and maybe a app.Release.config if you create one.  Deploying this via Octopus won't invoke the XML transformation.&lt;/p&gt;

&lt;p&gt;The trick is to rename the app.Release.config to be the name of the final config file produced by the build along with the 'exe' extension in it and to make sure in Visual Studio you set the build to Copy Always on the MyApp.exe.Release.config file.&lt;/p&gt;

&lt;p&gt;So for example if your project is called MyApp and you have an app.config and app.Release.config, open Windows Explorer and rename it to MyApp.exe.Release.config.  Visual Studio won't allow you to rename these files that are dependent on another so you now have to open up MyApp.csproj and alter the references from app.Release.config to MyApp.exe.Release.config&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;Content Include="App.config" /&amp;gt;
&amp;lt;Content Include="MyApp.exe.Release.config" &amp;gt;
    &amp;lt;DependentUpon&amp;gt;App.Config&amp;lt;/DependentUpon&amp;gt;
&amp;lt;/Content&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Go into VS, Reload All when it prompts you and set the Copy to Output Directory value to Copy Always&lt;/p&gt;

&lt;p&gt;&lt;img src="http://i.imgur.com/E8Kbezh.jpg" alt="VS Property Window" /&gt;&lt;/p&gt;

&lt;p&gt;Now when you deploy Octopus should run the transformation and replace connection strings etc as you would expect.&lt;/p&gt;
</a10:content></item><item><guid isPermaLink="true">http://blog.jonathanchannon.com/2013/11/07/using-git-to-update-youtrack-via-teamcity/</guid><link>http://blog.jonathanchannon.com/2013/11/07/using-git-to-update-youtrack-via-teamcity/</link><title>Using Git to update YouTrack via TeamCity</title><description>&lt;p&gt;This post is mainly a reminder for me as I keep forgetting the command in Git to integrate commits to YouTrack items.&lt;/p&gt;

&lt;p&gt;YouTrack uses TeamCity to get the information about the commits and then scans the commit comment for a YouTrack item id and any commands that it can apply such as item status or time spent on said item.&lt;/p&gt;

&lt;p&gt;There is some documentation &lt;a href="http://confluence.jetbrains.com/display/YTD4/Executing+Commands+from+Comment+to+VCS+Commit"&gt;here&lt;/a&gt; but its not the greatest in terms of clarity and I've spoken to &lt;a href="https://twitter.com/hhariri"&gt;Hadi Hariri&lt;/a&gt; from JetBrains about improving this so hopefully they're working on it.&lt;/p&gt;

&lt;p&gt;Anyhow here's some example Git commands to wire it all up&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git commit -am "I fixed a massive bug #PROJ-158 Complete"
git commit -am "I fixed a massive bug #PROJ-158 Complete add work 1h"
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The first command will update the status of YouTrack item #PROJ-158 to Complete.  The second item will do the same but also add Time Tracking information to the item in YouTrack.&lt;/p&gt;

&lt;p&gt;Hope that helps, Happy Coding!&lt;/p&gt;
</description><pubDate>Thu, 07 Nov 2013 00:00:00 Z</pubDate><a10:updated>2013-11-07T00:00:00Z</a10:updated><a10:content type="text">&lt;p&gt;This post is mainly a reminder for me as I keep forgetting the command in Git to integrate commits to YouTrack items.&lt;/p&gt;

&lt;p&gt;YouTrack uses TeamCity to get the information about the commits and then scans the commit comment for a YouTrack item id and any commands that it can apply such as item status or time spent on said item.&lt;/p&gt;

&lt;p&gt;There is some documentation &lt;a href="http://confluence.jetbrains.com/display/YTD4/Executing+Commands+from+Comment+to+VCS+Commit"&gt;here&lt;/a&gt; but its not the greatest in terms of clarity and I've spoken to &lt;a href="https://twitter.com/hhariri"&gt;Hadi Hariri&lt;/a&gt; from JetBrains about improving this so hopefully they're working on it.&lt;/p&gt;

&lt;p&gt;Anyhow here's some example Git commands to wire it all up&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git commit -am "I fixed a massive bug #PROJ-158 Complete"
git commit -am "I fixed a massive bug #PROJ-158 Complete add work 1h"
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The first command will update the status of YouTrack item #PROJ-158 to Complete.  The second item will do the same but also add Time Tracking information to the item in YouTrack.&lt;/p&gt;

&lt;p&gt;Hope that helps, Happy Coding!&lt;/p&gt;
</a10:content></item><item><guid isPermaLink="true">http://blog.jonathanchannon.com/2013/10/21/running-mocha-tests-with-sublime-text/</guid><link>http://blog.jonathanchannon.com/2013/10/21/running-mocha-tests-with-sublime-text/</link><title>Running Mocha tests within Sublime Text</title><description>&lt;p&gt;I spend most of my day in Visual Studio with lots of the goodies an IDE can offer.  One of them being able to run your tests from a keystroke.&lt;/p&gt;

&lt;p&gt;In a bid to expand my mind I'm working on a little project that is made up of JS entirely so I've dug out &lt;a href="http://sublimetext.com"&gt;Sublime Text&lt;/a&gt;. It has lots of plugins that are very handy, especially &lt;a href="https://github.com/victorporof/Sublime-HTMLPrettify"&gt;Sublime-HTMLPrettify&lt;/a&gt; which will tidy your HTML, CSS &amp;amp; JS for you.&lt;/p&gt;

&lt;p&gt;When writing tests for JS there are many libraries you can use but I've chosen &lt;a href="http://visionmedia.github.io/mocha/"&gt;Mocha&lt;/a&gt; for now.  The one thing I couldn't work out was to run my tests within Sublime Text until now.&lt;/p&gt;

&lt;h3&gt;Build System&lt;/h3&gt;

&lt;p&gt;Sublime allows you to have build systems a bit like an IDE so you can tell it what to do when you invoke it via &lt;kbd&gt;cmd&lt;/kbd&gt;+&lt;kbd&gt;B&lt;/kbd&gt;.&lt;/p&gt;

&lt;p&gt;To get Mocha to run we need to create a new build system. To do this click Tools - Build System - New Build System and paste in the below:&lt;/p&gt;

</description><pubDate>Sun, 20 Oct 2013 23:00:00 Z</pubDate><a10:updated>2013-10-20T23:00:00Z</a10:updated><a10:content type="text">&lt;p&gt;I spend most of my day in Visual Studio with lots of the goodies an IDE can offer.  One of them being able to run your tests from a keystroke.&lt;/p&gt;

&lt;p&gt;In a bid to expand my mind I'm working on a little project that is made up of JS entirely so I've dug out &lt;a href="http://sublimetext.com"&gt;Sublime Text&lt;/a&gt;. It has lots of plugins that are very handy, especially &lt;a href="https://github.com/victorporof/Sublime-HTMLPrettify"&gt;Sublime-HTMLPrettify&lt;/a&gt; which will tidy your HTML, CSS &amp;amp; JS for you.&lt;/p&gt;

&lt;p&gt;When writing tests for JS there are many libraries you can use but I've chosen &lt;a href="http://visionmedia.github.io/mocha/"&gt;Mocha&lt;/a&gt; for now.  The one thing I couldn't work out was to run my tests within Sublime Text until now.&lt;/p&gt;

&lt;h3&gt;Build System&lt;/h3&gt;

&lt;p&gt;Sublime allows you to have build systems a bit like an IDE so you can tell it what to do when you invoke it via &lt;kbd&gt;cmd&lt;/kbd&gt;+&lt;kbd&gt;B&lt;/kbd&gt;.&lt;/p&gt;

&lt;p&gt;To get Mocha to run we need to create a new build system. To do this click Tools - Build System - New Build System and paste in the below:&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;pre&gt;&lt;code&gt;{
    "cmd": ["make"],
    "file_regex": "^(..[^:]*):([0-9]+):?([0-9]+)?:? (.*)$",
    "working_dir": "${project_path:${folder:${file_path}}}",
    "selector": "source.makefile",
    "shell": true,
    "variants": [{
        "name": "Clean",
        "cmd": ["make", "clean"]
    }]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Click Save and call it Mocha&lt;/p&gt;

&lt;p&gt;Now when you have a project go to Tools - Build System and select Mocha&lt;/p&gt;

&lt;h3&gt;Make file&lt;/h3&gt;

&lt;p&gt;A Make file is a script that allows you to execute various commands and its what our build system looks for when we tell Sublime to build our project. We need a file called &lt;code&gt;makefile&lt;/code&gt; in the root of our project.  Inside that &lt;code&gt;makefile&lt;/code&gt; we can invoke Mocha to run our tests.&lt;/p&gt;

&lt;p&gt;Place this in your &lt;code&gt;makefile&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;test:
    mocha --recursive --reporter spec moviebucketlist.tests/*.js
.PHONY: test
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now when you invoke the build system via &lt;kbd&gt;cmd&lt;/kbd&gt;+&lt;kbd&gt;B&lt;/kbd&gt; in Sublime it will execute Mocha and give you the results in the console of Sublime.  Mocha by default will look for a folder called &lt;code&gt;test&lt;/code&gt; and execute the tests inside it. If you have a different folder name you can append the folder name and wildcard to js files like I have done above.&lt;/p&gt;

&lt;p&gt;Happy Coding!&lt;/p&gt;
</a10:content></item><item><guid isPermaLink="true">http://blog.jonathanchannon.com/2013/10/01/blogging-with-markdown-and-git/</guid><link>http://blog.jonathanchannon.com/2013/10/01/blogging-with-markdown-and-git/</link><title>Blogging with Markdown &amp; Deploying via Git - Introducing Sandra.Snow</title><description>&lt;p&gt;There are many markdown blogging engines out there such as &lt;a href="http://calepin.co/"&gt;Calepin&lt;/a&gt;, &lt;a href="http://scriptogr.am/"&gt;Scriptogram&lt;/a&gt; and even &lt;a href="http://wordpress.org/"&gt;WordPress&lt;/a&gt; allows you to write blog posts in Markdown but &lt;a href="https://github.com/Sandra/Sandra.Snow"&gt;Sandra.Snow&lt;/a&gt; tries to add something different.  Firstly, it is written in .Net and &lt;a href="http://nancyfx.org"&gt;Nancy&lt;/a&gt;, secondly its a static blog generator and finally it supports Git deployment.&lt;/p&gt;

&lt;p&gt;Even if you don't want to use Git deployment you can use FTP, its a great tool.  To write your blog post in Markdown you need a custom header in your file so it knows some information about your post.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;---
layout: post
category: Azure
title: Setting up a ServiceStack Service
---
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It then parses this information along with your Markdown into its engine, uses a Markdown view engine to convert the file content into HTML, assign model properties based on the header and creates a HTML file using the model via a Razor viewengine.&lt;/p&gt;

&lt;p&gt;The "layout" refers to the Razor file it uses to render the final HTML file.  This allows you to style your pages and blog posts whichever way you'd prefer.  These "layout" files should exist in the "_layouts" folder for your site template.  The site template is a set of files and folders that Sandra.Snow uses to produce the final static website.&lt;/p&gt;

&lt;p&gt;The "category" or "categories" property, you can use both for singular or multiple comma-seperated values that refer to the category/categories of your blog post.&lt;/p&gt;

&lt;p&gt;The "title" should hopefully be self explanatory!&lt;/p&gt;

&lt;p&gt;You can optionally add an author and email properties to override the global config settings for example, if you wanted to allow guest author blog posts.  There is also an optional metadescription property you can use for SEO.
</description><pubDate>Mon, 30 Sep 2013 23:00:00 Z</pubDate><a10:updated>2013-09-30T23:00:00Z</a10:updated><a10:content type="text">&lt;p&gt;There are many markdown blogging engines out there such as &lt;a href="http://calepin.co/"&gt;Calepin&lt;/a&gt;, &lt;a href="http://scriptogr.am/"&gt;Scriptogram&lt;/a&gt; and even &lt;a href="http://wordpress.org/"&gt;WordPress&lt;/a&gt; allows you to write blog posts in Markdown but &lt;a href="https://github.com/Sandra/Sandra.Snow"&gt;Sandra.Snow&lt;/a&gt; tries to add something different.  Firstly, it is written in .Net and &lt;a href="http://nancyfx.org"&gt;Nancy&lt;/a&gt;, secondly its a static blog generator and finally it supports Git deployment.&lt;/p&gt;

&lt;p&gt;Even if you don't want to use Git deployment you can use FTP, its a great tool.  To write your blog post in Markdown you need a custom header in your file so it knows some information about your post.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;---
layout: post
category: Azure
title: Setting up a ServiceStack Service
---
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It then parses this information along with your Markdown into its engine, uses a Markdown view engine to convert the file content into HTML, assign model properties based on the header and creates a HTML file using the model via a Razor viewengine.&lt;/p&gt;

&lt;p&gt;The "layout" refers to the Razor file it uses to render the final HTML file.  This allows you to style your pages and blog posts whichever way you'd prefer.  These "layout" files should exist in the "_layouts" folder for your site template.  The site template is a set of files and folders that Sandra.Snow uses to produce the final static website.&lt;/p&gt;

&lt;p&gt;The "category" or "categories" property, you can use both for singular or multiple comma-seperated values that refer to the category/categories of your blog post.&lt;/p&gt;

&lt;p&gt;The "title" should hopefully be self explanatory!&lt;/p&gt;

&lt;p&gt;You can optionally add an author and email properties to override the global config settings for example, if you wanted to allow guest author blog posts.  There is also an optional metadescription property you can use for SEO.
&lt;!--excerpt--&gt;&lt;/p&gt;

&lt;h3&gt;Global Config&lt;/h3&gt;

&lt;p&gt;In the root of the site template is a snow.config file which is what Sandra.Snow uses to determine url format, where to look for posts and layouts and other related information. It is JSON formatted and looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  "blogTitle" : "Joe Bloggs Blog",
  "author" : "Mr.Guest",
  "email" : "guest@gmail.com",
  "siteUrl": "http://blog.joebloggs.com",
  "posts": "Snow/_posts",
  "layouts": "Snow/_layouts",
  "output": "../MYRelativeWebsiteFolder",
  "urlFormat": "yyyy/MM/dd/slug",
  "copyDirectories": [
    "Snow/images =&amp;gt; images",
    "Snow/js =&amp;gt; js",
    "Snow/css =&amp;gt; css"
  ],
  "processFiles": [{
    "file": "Snow/index.cshtml",
    "loop": "Posts"
  },{
    "file": "Snow/category.cshtml",
    "loop": "Categories"
  },{
    "file": "Snow/categories.cshtml =&amp;gt; categories"
  },{
    "file": "Snow/archive.cshtml =&amp;gt; archive"
  },{
    "file": "Snow/about.cshtml =&amp;gt; about"
  },{
    "file": "Snow/contact.cshtml =&amp;gt; contact"
  },{
    "file": "feed.xml",
    "loop": "RSS"
  },{
    "file": "sitemap.xml",
    "loop": "sitemap"
  }]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here is an explanation:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;"blogTitle" : The title of the blog you want to appear on your RSS feed&lt;/li&gt;
&lt;li&gt;"author" : The author's name&lt;/li&gt;
&lt;li&gt;"email" : The author's email.(You can use an &lt;a href="https://github.com/Sandra/Sandra.Snow/wiki/Gravatar-Support"&gt;HTMLHelper&lt;/a&gt; in the view that gets the author's Gravatar from the global/post settings)&lt;/li&gt;
&lt;li&gt;"siteUrl": "This is used to enable Disqus support. Simply use an &lt;a href="https://github.com/Sandra/Sandra.Snow/wiki/Disqus-Support"&gt;HTMLHelper&lt;/a&gt; to render Disqus comments"&lt;/li&gt;
&lt;li&gt;"posts" : The location of the markdown files&lt;/li&gt;
&lt;li&gt;"layouts" : The location of the layout files&lt;/li&gt;
&lt;li&gt;"output" : The location where Sandra.Snow will put the static HTML. This is relative&lt;/li&gt;
&lt;li&gt;"urlFormat" : The format of the URL to your blog post&lt;/li&gt;
&lt;li&gt;"copyDirectories" : The directories in your template that it will copy to the output&lt;/li&gt;
&lt;li&gt;&lt;p&gt;"processFiles" : This takes an object of the filename and property information on how to render the file.  Each file/view will be called and rendered with model information availble.  The model information available to these views are shown below:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public List&amp;lt;Post&amp;gt; PostsInCategory { get; set; }
public Dictionary&amp;lt;int, Dictionary&amp;lt;int, List&amp;lt;Post&amp;gt;&amp;gt;&amp;gt; PostsGroupedByYearThenMonth { get; set; }
public List&amp;lt;Post&amp;gt; Posts { get; set; }
public List&amp;lt;Post&amp;gt; PostsPaged { get; set; }


public bool HasPreviousPage { get; set; }
public bool HasNextPage { get; set; }
public int NextPage { get; set; }
public int PreviousPage { get; set; }
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In the standard website template there are category, categories, about and index *.cshtml pages which accept this model information and render the relevant information. Based on the file name you can guess what each file outputs.  The "loop" in the settings is used internally by Sandra.Snow to process the relevant data. For example "RSS" creates a RSS file based on the list of posts while Posts/Categories create sub-directories for the relevant model type eg/categories/posts.  "sitemap" will use the &lt;code&gt;List&amp;lt;Post&amp;gt;&lt;/code&gt; to create a sitemap.xml in the root of your blog. &lt;/p&gt;

&lt;p&gt;As Sandra.Snow is a static HTML generator it will create folders with the relevant name for the post or file named in the config file eg/&lt;code&gt;http://mydomain.com/2013/08/18/this-is-a-great-article&lt;/code&gt; or &lt;code&gt;http://mydomain.com/categories&lt;/code&gt; and create a &lt;code&gt;index.html&lt;/code&gt; file for each folder.  In the root of the website it will create a &lt;code&gt;index.html&lt;/code&gt; with 10 blog posts inside it.  If you have 100 markdown posts it will it will page this for you and create links to &lt;code&gt;http://mydomain.com/page2&lt;/code&gt; etc.  If you use &lt;code&gt;&amp;lt;!--excerpt--&amp;gt;&lt;/code&gt; in your Markdown it will read up to that point so you can click a "read more" link otherwise it will use the whole Markdown content.    If you look at the model properties you'll see your index layout view can tell if there is a next/previous page and therefore create the relevant links in the HTML.&lt;/p&gt;

&lt;p&gt;Once you run the Sandra.Snow exe it will output the HTML and you can then FTP your files to your website.&lt;/p&gt;

&lt;p&gt;Check out the &lt;a href="https://github.com/Sandra/Sandra.Snow/wiki"&gt;wiki&lt;/a&gt; for more details about other HTMLHelpers such as Google Analytics.&lt;/p&gt;

&lt;h3&gt;Git Integration&lt;/h3&gt;

&lt;p&gt;FTP is so 2001 so Sandra.Snow has a website called Sandra.Snow.Barbato which allows you to access it (final URL to be confirmed) and log in with your Github credentials.  It will then give you a list of your repositories, the idea being one of them is your blog with the markdown posts and snow.config etc.  A &lt;a href="https://github.com/Sandra/Sandra.Snow.BarbatoTemplate"&gt;base template&lt;/a&gt; is available in the Sandra repository for you to fork.  You can then choose whether you'd like to deploy to another Git repository that supports Git deployment eg/Azure, AppHarbor, Heroku or you can select FTP.  In either scenario, enter your details and off you go. The website will use Sandra.Snow to create the output and it will then wire it over to your chosen destination.  &lt;/p&gt;

&lt;p&gt;Sandra.Snow.Barbato is also setup to handle Github hooks so in Github if you tell your repository to do a post commit hook to the website, after you write a new blog post and push to Github it will post to the website and know if you've previously logged in and if so generate the HTML and re-deploy your blog.  It will also push the generated content back to your Github repository on the master branch. Very nice!&lt;/p&gt;

&lt;h3&gt;Setting up Sandra.Snow.Barbato&lt;/h3&gt;

&lt;p&gt;One you have forked the Barbato template you can begin to style your blog pages.  Obviously every time you want to make a style change you want to see the results.  There are 2 ways to do this.  i) Run Sandra.Snow locally, setup a webserver eg/IISExpress to point to the Snow output directory and open up your browser to see the changes. Keep making changes to the *.cshtml and *.css files until happy ii) Make the changes in your repo, sign up with Sandra.Snow.Barbato and go to your domain to check the changes that were deployed.&lt;/p&gt;

&lt;h4&gt;Azure&lt;/h4&gt;

&lt;p&gt;If deploying to Azure you must have a .deployment file in the root of your repository that contains:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[config]
project = Website
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is needed because when your template repository is pushed to Azure it needs to know what to deploy. This simply tells it to use the Website folder ie.the output folder from Sandra.Snow.&lt;/p&gt;

&lt;h4&gt;Github Pages&lt;/h4&gt;

&lt;p&gt;If deploying to Github you need a few things. Your repository needs to be called &lt;code&gt;username.github.io&lt;/code&gt;. You then need to create a CNAME file in your repo that has the domain you will be using inside it. Finally you need to setup the DNS on your domain to point to &lt;code&gt;username.github.io&lt;/code&gt; by creating a CNAME record in your DNS Manager. What you'll have to probably do is clone your &lt;code&gt;username.github.io&lt;/code&gt; repo and run Snow and set the output setting in snow.config to the path of your &lt;code&gt;username.github.io&lt;/code&gt; folder. You can then push the changes to Github. &lt;/p&gt;

&lt;h3&gt;Wordpress Migration&lt;/h3&gt;

&lt;p&gt;My blog was previously using Wordpress so I needed to get my data out.  The most common referred to tool was &lt;a href="https://github.com/dreikanter/wp2md"&gt;wp2md&lt;/a&gt; which uses Python to go through the exported Wordpress content and then convert to Markdown.  For some reason I didn't go with that choice and went with &lt;a href="http://heckyesmarkdown.com/"&gt;http://heckyesmarkdown.com/&lt;/a&gt;.  Its a bit more work because you have to give it your previous URLs to your blog posts and it reads the source of the page and converts it to Markdown.  It worked brilliantly for me.  I had to make a few changes on the output it provided by generally it was very good.&lt;/p&gt;

&lt;p&gt;As I didn't want to worry about HTTP 302, I made sure I saved my markdown files as the urls are on my live site so &lt;a href="http://blog.jonathanchannon.com/2012/12/19/why-use-nancyfx/"&gt;http://blog.jonathanchannon.com/2012/12/19/why-use-nancyfx/&lt;/a&gt; was saved in a file called &lt;code&gt;2012-12-19-why-use-nancyfx.md&lt;/code&gt;. This file naming format is currently enforced so Snow can gather date and slug information(unsafe characters in the slug/title for URLs will be removed).&lt;/p&gt;

&lt;p&gt;I then went through addind the meta headers to tell Sandra.Snow a bit more about the posts and also added in the &lt;code&gt;&amp;lt;!--excerpt--&amp;gt;&lt;/code&gt; information so not to render the whole blog content on the home pages.&lt;/p&gt;

&lt;p&gt;I then went through and styled the master page &lt;code&gt;default.cshtml&lt;/code&gt; in the _layouts folder as well as the &lt;code&gt;post.cshtml&lt;/code&gt; and the other files in the root of the site template folder.&lt;/p&gt;

&lt;p&gt;Once done I ran the .exe file to generate my content.  One of the great things about Sandra.Snow is its speed. It takes less than a second to do 100 blog posts, luckily I only have 25 so its really fast.  I opened up a browser and checked my files and if some styling needed tweaking I could do so and re-run.  Once all ok I can deploy or push the template folder to Github, setup the post commit hook and then use Sandra.Snow.Barbato to handle deployment from now on.&lt;/p&gt;

&lt;h3&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;If you're a Git and Markdown user and want to create a blog with complete simplicity this is a great tool.  No more messy Wordpress, no more running exe's on your machine (unless you want to), its completely automated apart from writing the blog posts!  In fact I'm so happy with this project, this blog is using it!  Give it a try and if you like the look of it get involved with its development.  &lt;a href="https://github.com/Sandra/Sandra.Snow"&gt;Sandra.Snow&lt;/a&gt; the new modern, simplistic and effective tool for blogging.&lt;/p&gt;
</a10:content></item><item><guid isPermaLink="true">http://blog.jonathanchannon.com/2013/09/20/returning-multiple-fake-objects-with-fakeiteasy/</guid><link>http://blog.jonathanchannon.com/2013/09/20/returning-multiple-fake-objects-with-fakeiteasy/</link><title>Returning multiple fake objects with FakeItEasy</title><description>&lt;p&gt;I was recently writing some unit tests where I needed to test that multiple calls to an interface returned different objects.  &lt;/p&gt;

&lt;p&gt;With &lt;a href="https://github.com/FakeItEasy/FakeItEasy"&gt;FakeItEasy&lt;/a&gt; this is easy:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A.CallTo(() =&amp;gt; myInterface.GetSomething(1)).Returns(new Something())
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;All very nice, but now if I have multiple calls to &lt;code&gt;myInterface&lt;/code&gt; I have to execute the above statement 'x' amount of times:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[Fact]
public void Should_Do_Something()
{
  var myInterface = A.Fake&amp;lt;IApplication&amp;gt;();
  A.CallTo(() =&amp;gt; myInterface.GetSomething(1)).Returns(new Something());
  A.CallTo(() =&amp;gt; myInterface.GetSomething(2)).Returns(new Something());
  A.CallTo(() =&amp;gt; myInterface.GetSomething(3)).Returns(new Something());

  var result = sut.DoSomething(myInterface);

  Assert.Equal("Super Duper", result);
}
&lt;/code&gt;&lt;/pre&gt;

</description><pubDate>Thu, 19 Sep 2013 23:00:00 Z</pubDate><a10:updated>2013-09-19T23:00:00Z</a10:updated><a10:content type="text">&lt;p&gt;I was recently writing some unit tests where I needed to test that multiple calls to an interface returned different objects.  &lt;/p&gt;

&lt;p&gt;With &lt;a href="https://github.com/FakeItEasy/FakeItEasy"&gt;FakeItEasy&lt;/a&gt; this is easy:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A.CallTo(() =&amp;gt; myInterface.GetSomething(1)).Returns(new Something())
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;All very nice, but now if I have multiple calls to &lt;code&gt;myInterface&lt;/code&gt; I have to execute the above statement 'x' amount of times:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[Fact]
public void Should_Do_Something()
{
  var myInterface = A.Fake&amp;lt;IApplication&amp;gt;();
  A.CallTo(() =&amp;gt; myInterface.GetSomething(1)).Returns(new Something());
  A.CallTo(() =&amp;gt; myInterface.GetSomething(2)).Returns(new Something());
  A.CallTo(() =&amp;gt; myInterface.GetSomething(3)).Returns(new Something());

  var result = sut.DoSomething(myInterface);

  Assert.Equal("Super Duper", result);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;!--excerpt--&gt;

&lt;p&gt;There is a tidier way to do the above where you can return specific objects and its called &lt;code&gt;ReturnsLazily&lt;/code&gt;.  Lets take a look at this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class Employee
{
    public string Name { get; set; }
}

public interface IEmployeeRepository
{
    Employee GetEmployeeById(int id);
}

public class App
{
    private readonly IEmployeeRepository employeeRepository;

    public App(IEmployeeRepository employeeRepository)
    {
        this.employeeRepository = employeeRepository;
    }

    public string GetNamesAsCsv(int[] ids)
    {
        var employees = ids.Select(id =&amp;gt; employeeRepository.GetEmployeeById(id).Name);
        return string.Join(",", employees);
    }
}

public class AppTests
{
    [Fact]
    public void AppReturnsNamesAsCsv()
    {
        //Given
        var employees = new Dictionary&amp;lt;int, Employee&amp;gt;
        {
            { 1, new Employee { Name = "Moss"} },
            { 2, new Employee { Name = "Roy"} },
        };

        var fakeRepository = A.Fake&amp;lt;IEmployeeRepository&amp;gt;();
        A.CallTo(() =&amp;gt; fakeRepository.GetEmployeeById(A&amp;lt;int&amp;gt;.Ignored))
            .ReturnsLazily&amp;lt;Employee, int&amp;gt;(id =&amp;gt; employees[id]);

        var app = new App(fakeRepository);

        //When
        var result = app.GetNamesAsCsv(employees.Keys.ToArray());

        //Then
        Assert.Equal("Moss,Roy", result);
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We have an &lt;code&gt;Employee&lt;/code&gt; object, a &lt;code&gt;IEmployeeRepository&lt;/code&gt; which returns an &lt;code&gt;Employee&lt;/code&gt; object and an App that returns a CSV.  We then want to test this and make sure we get back a CSV from multiple objects.&lt;/p&gt;

&lt;p&gt;So we set our fake setup and say that when &lt;code&gt;GetEmployeeById&lt;/code&gt; is called we want to return a specific object.  Our App class will call &lt;code&gt;GetEmployeeById&lt;/code&gt; twice with the id of 1 and 2.  This is done by passing in &lt;code&gt;employees.Keys.ToArray()&lt;/code&gt; to our GetNamesAsCsv method under test. &lt;/p&gt;

&lt;p&gt;When this is called with the id we want to return specific objects &lt;code&gt;.ReturnsLazily&amp;lt;Employee, int&amp;gt;(id =&amp;gt; employees[id]);&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This says we want to return an Employee and the argument in the repository call is an int.  We can then use that to return a specific object based on that id which is where the &lt;code&gt;Dictionary&amp;lt;int, Employee&amp;gt;&lt;/code&gt; comes in handy.  Based on the key it will return either an Employee called Moss or Roy.  Our &lt;code&gt;GetNamesAsCsv&lt;/code&gt; will then join Moss &amp;amp; Roy together as a CSV and we can assert that our method works.&lt;/p&gt;

&lt;p&gt;Hope that helps someone!&lt;/p&gt;
</a10:content></item><item><guid isPermaLink="true">http://blog.jonathanchannon.com/2013/09/16/enabling-cors-in-iisexpress/</guid><link>http://blog.jonathanchannon.com/2013/09/16/enabling-cors-in-iisexpress/</link><title>Enabling CORS in IISExpress</title><description>&lt;p&gt;I was playing around with &lt;a href="https://github.com/wordnik/swagger-ui"&gt;swagger-ui&lt;/a&gt; and was trying to point it to a local endpoint that I started with IIS Express.  I was getting an error saying that it needed the endpoint to accept Access-Control-Allow-Origin requests.&lt;/p&gt;

&lt;p&gt;I went Googling and it couldn't find anything specific to IIS Express but managed to use some guidance for full blown IIS.&lt;/p&gt;

&lt;p&gt;The solution is to go to &lt;code&gt;C:\Program Files (x86)\IIS Express\AppServer&lt;/code&gt; and open the &lt;code&gt;applicationhost.config&lt;/code&gt; file.&lt;/p&gt;

&lt;p&gt;Search for &lt;code&gt;httpProtocol&lt;/code&gt; and you should see this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;httpProtocol&amp;gt;
    &amp;lt;customHeaders&amp;gt;
        &amp;lt;clear /&amp;gt;
        &amp;lt;add name="X-Powered-By" value="ASP.NET" /&amp;gt;
    &amp;lt;/customHeaders&amp;gt;
    &amp;lt;redirectHeaders&amp;gt;
        &amp;lt;clear /&amp;gt;
    &amp;lt;/redirectHeaders&amp;gt;
&amp;lt;/httpProtocol&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now add this to the &lt;code&gt;customHeaders&lt;/code&gt; node:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;add name="Access-Control-Allow-Origin" value="*" /&amp;gt;
&amp;lt;add name="Access-Control-Allow-Headers" value="Content-Type" /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Just bear in mind this opens up your webserver so you may need to find something alternative for a live production environment.&lt;/p&gt;

&lt;p&gt;Anyway you should now be able to start accepting requests via CORS when you fire up IISExpress&lt;/p&gt;
</description><pubDate>Sun, 15 Sep 2013 23:00:00 Z</pubDate><a10:updated>2013-09-15T23:00:00Z</a10:updated><a10:content type="text">&lt;p&gt;I was playing around with &lt;a href="https://github.com/wordnik/swagger-ui"&gt;swagger-ui&lt;/a&gt; and was trying to point it to a local endpoint that I started with IIS Express.  I was getting an error saying that it needed the endpoint to accept Access-Control-Allow-Origin requests.&lt;/p&gt;

&lt;p&gt;I went Googling and it couldn't find anything specific to IIS Express but managed to use some guidance for full blown IIS.&lt;/p&gt;

&lt;p&gt;The solution is to go to &lt;code&gt;C:\Program Files (x86)\IIS Express\AppServer&lt;/code&gt; and open the &lt;code&gt;applicationhost.config&lt;/code&gt; file.&lt;/p&gt;

&lt;p&gt;Search for &lt;code&gt;httpProtocol&lt;/code&gt; and you should see this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;httpProtocol&amp;gt;
    &amp;lt;customHeaders&amp;gt;
        &amp;lt;clear /&amp;gt;
        &amp;lt;add name="X-Powered-By" value="ASP.NET" /&amp;gt;
    &amp;lt;/customHeaders&amp;gt;
    &amp;lt;redirectHeaders&amp;gt;
        &amp;lt;clear /&amp;gt;
    &amp;lt;/redirectHeaders&amp;gt;
&amp;lt;/httpProtocol&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now add this to the &lt;code&gt;customHeaders&lt;/code&gt; node:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;add name="Access-Control-Allow-Origin" value="*" /&amp;gt;
&amp;lt;add name="Access-Control-Allow-Headers" value="Content-Type" /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Just bear in mind this opens up your webserver so you may need to find something alternative for a live production environment.&lt;/p&gt;

&lt;p&gt;Anyway you should now be able to start accepting requests via CORS when you fire up IISExpress&lt;/p&gt;
</a10:content></item><item><guid isPermaLink="true">http://blog.jonathanchannon.com/2013/09/12/keeping-sql-data-organised-in-integration-tests/</guid><link>http://blog.jonathanchannon.com/2013/09/12/keeping-sql-data-organised-in-integration-tests/</link><title>Keeping SQL Data Organised in Integration Tests</title><description>&lt;p&gt;In my latest project I had kept my solution tidy with my main app project, my unit test project and integration test project. I tend to stick with a naming convention such as MainApp, MainApp.Tests.Unit &amp;amp; MainApp.Tests.Integration.&lt;/p&gt;

&lt;p&gt;I had begun writing my integration tests for a repository that hits the database and returns data. Currently it was one method being called in the repository.  &lt;a href="http://xunit.codeplex.com/"&gt;xUnit&lt;/a&gt; allows you to setup any test dependencies in the constructor of your test class.  It also allows you to do any tidying up in a Dispose method if you implement IDisposable although this is &lt;a href="http://xunit.codeplex.com/wikipage?title=Comparisons&amp;amp;referringTitle=Home#note2"&gt;frowned upon&lt;/a&gt;.  However I felt for my needs I would implement this.&lt;/p&gt;

&lt;p&gt;I  was creating data in the database in the constructor which will get called before the test runs, retrieving data in the test, asserting and then deleting all data and resetting the auto-incrementing from the tables in the Dispose method.&lt;/p&gt;

&lt;p&gt;This was working perfectly until I wanted to test another method on my repository.&lt;/p&gt;

&lt;p&gt;I now needed to add data for my new method but realised if I added different data to the database in the constructor, I would be creating unnecessary data unrelated to the test.&lt;/p&gt;

&lt;p&gt;My options were to move the constructor logic into separate methods and then call the methods in the test or have separate test classes per method in the repo.  Both were a not an ideal solution and quite frankly verbose, ugly and not best practice.
</description><pubDate>Wed, 11 Sep 2013 23:00:00 Z</pubDate><a10:updated>2013-09-11T23:00:00Z</a10:updated><a10:content type="text">&lt;p&gt;In my latest project I had kept my solution tidy with my main app project, my unit test project and integration test project. I tend to stick with a naming convention such as MainApp, MainApp.Tests.Unit &amp;amp; MainApp.Tests.Integration.&lt;/p&gt;

&lt;p&gt;I had begun writing my integration tests for a repository that hits the database and returns data. Currently it was one method being called in the repository.  &lt;a href="http://xunit.codeplex.com/"&gt;xUnit&lt;/a&gt; allows you to setup any test dependencies in the constructor of your test class.  It also allows you to do any tidying up in a Dispose method if you implement IDisposable although this is &lt;a href="http://xunit.codeplex.com/wikipage?title=Comparisons&amp;amp;referringTitle=Home#note2"&gt;frowned upon&lt;/a&gt;.  However I felt for my needs I would implement this.&lt;/p&gt;

&lt;p&gt;I  was creating data in the database in the constructor which will get called before the test runs, retrieving data in the test, asserting and then deleting all data and resetting the auto-incrementing from the tables in the Dispose method.&lt;/p&gt;

&lt;p&gt;This was working perfectly until I wanted to test another method on my repository.&lt;/p&gt;

&lt;p&gt;I now needed to add data for my new method but realised if I added different data to the database in the constructor, I would be creating unnecessary data unrelated to the test.&lt;/p&gt;

&lt;p&gt;My options were to move the constructor logic into separate methods and then call the methods in the test or have separate test classes per method in the repo.  Both were a not an ideal solution and quite frankly verbose, ugly and not best practice.
&lt;!--excerpt--&gt;&lt;/p&gt;

&lt;h2&gt;The Solution&lt;/h2&gt;

&lt;p&gt;I started playing with the attributes on my tests to see if xUnit offered me something and was chuffed to find the &lt;code&gt;BeforeAfterTestAttribute&lt;/code&gt;.  This does exactly what it says on the tin.  Its an abstract class that you inherit from for your own implementation and overide the &lt;code&gt;Before&lt;/code&gt; and &lt;code&gt;After&lt;/code&gt; methods;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class RepoMethod1BeforeAfter : BeforeAfterTestAttribute
{
    public override void After(MethodInfo methodUnderTest)
    {
      //Insert data into tables
    }

    public override void Before(MethodInfo methodUnderTest)
    {
      //Drop data from tables
    }
}

[Fact]
[RepoMethod1BeforeAfter]
public void RepoMethod1_Should_be_Awesome()
{
  //Check it's awesome
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can then put an attribute on the relevant tests that need to have specific data inserted/deleted and it keeps the design of your test class follow best practices as well as not implementing IDisposable.&lt;/p&gt;

&lt;p&gt;The only thing I can spot as a slight issue is remembering to put the attribute on your tests but I think that'll be quite obvious when your tests start failing!&lt;/p&gt;
</a10:content></item><item><guid isPermaLink="true">http://blog.jonathanchannon.com/2013/09/11/comparing-object-instances-with-fakeiteasy/</guid><link>http://blog.jonathanchannon.com/2013/09/11/comparing-object-instances-with-fakeiteasy/</link><title>Comparing object instances with FakeItEasy</title><description>&lt;p&gt;I had the task of writing a new application recently and of course I chose &lt;a href="http://nancyfx.org"&gt;Nancy&lt;/a&gt;.  One of the many great reasons is the testing capabilites it offers (For more on that see &lt;a href="http://www.marcusoft.net/2013/01/NancyTesting1.html"&gt;this&lt;/a&gt; great series of articles).&lt;/p&gt;

&lt;p&gt;The basics of a test with Nancy looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[Fact]
public void Should_return_status_ok_when_route_exists()
{
    // Given
    var bootstrapper = new DefaultNancyBootstrapper();
    var browser = new Browser(bootstrapper);

    // When
    var result = browser.Get("/", with =&amp;gt; {
        with.HttpRequest();
    });

    // Then
    Assert.Equal(HttpStatusCode.OK, result.StatusCode);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You set up a bootstrapper, this can be your live one or an inherited version of your live one with dependencies changed to mocks for example or use the &lt;code&gt;ConfigurableBootstrapper&lt;/code&gt;.&lt;/p&gt;

</description><pubDate>Tue, 10 Sep 2013 23:00:00 Z</pubDate><a10:updated>2013-09-10T23:00:00Z</a10:updated><a10:content type="text">&lt;p&gt;I had the task of writing a new application recently and of course I chose &lt;a href="http://nancyfx.org"&gt;Nancy&lt;/a&gt;.  One of the many great reasons is the testing capabilites it offers (For more on that see &lt;a href="http://www.marcusoft.net/2013/01/NancyTesting1.html"&gt;this&lt;/a&gt; great series of articles).&lt;/p&gt;

&lt;p&gt;The basics of a test with Nancy looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[Fact]
public void Should_return_status_ok_when_route_exists()
{
    // Given
    var bootstrapper = new DefaultNancyBootstrapper();
    var browser = new Browser(bootstrapper);

    // When
    var result = browser.Get("/", with =&amp;gt; {
        with.HttpRequest();
    });

    // Then
    Assert.Equal(HttpStatusCode.OK, result.StatusCode);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You set up a bootstrapper, this can be your live one or an inherited version of your live one with dependencies changed to mocks for example or use the &lt;code&gt;ConfigurableBootstrapper&lt;/code&gt;.&lt;/p&gt;

&lt;!--excerpt--&gt;

&lt;p&gt;In my scenario I was testing that when a route got called something on an interface was called with an instance of an object.&lt;/p&gt;

&lt;p&gt;I had the object available in the test, I passed it to my fake interface and asserted that the call happened.&lt;/p&gt;

&lt;p&gt;Here's an example of what the route and test might look like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public class ApiModule : NancyModule
{
    public ApiModule(IScheduleRepository scheduleRepository)
        : base("/api/schedules")
    {
        Post["/"] = parameters =&amp;gt;
        {
            var result = this.BindAndValidate&amp;lt;Schedule&amp;gt;();

            if (!ModelValidationResult.IsValid)
            {
                return HttpStatusCode.UnprocessableEntity;
            }

            var conflict = scheduleRepository.CheckForConflict(result);

            return HttpStatusCode.Created;
        };
    }
}

[Fact]
public void Creating_Schedule_Entry_Should_Check_For_Conflicts()
{
    //Given
    var fakeScheduleRepository = A.Fake&amp;lt;IScheduleRepository&amp;gt;();
    var model = GetModel();

    var browser = new Browser(GetBootstrapper(scheduleRepository:fakeScheduleRepository));

    //When
    var result = browser.Post("/api/schedules", with =&amp;gt;
    {
        with.HttpRequest();
        with.JsonBody(model);
    });

    //Then
    A.CallTo(() =&amp;gt; fakeScheduleRepository.CheckForConflict(model)).MustHaveHappened();
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The test is using &lt;a href="http://xunit.codeplex.com/"&gt;xUnit&lt;/a&gt; and &lt;a href="https://github.com/FakeItEasy/FakeItEasy"&gt;FakeItEasy&lt;/a&gt; for creating fakes/mocks or whatever you choose to call them and the test will pass if the call to &lt;code&gt;fakeScheduleRepository.CheckForConflict&lt;/code&gt; was called with the model object.&lt;/p&gt;

&lt;h2&gt;The test fails!&lt;/h2&gt;

&lt;p&gt;The reason for the test failing is because...? That's right, the object that is passed into the call on IScheduleRepository in the route is different to the one in the test.&lt;/p&gt;

&lt;p&gt;We could override Equals on our model object but that's not a great approach, we could hope that if we create an &lt;code&gt;IEqualityComparer&amp;lt;Schedule&amp;gt;&lt;/code&gt; we could pass that in somewhere but from what I've seen that's not possible so how do we get our test to pass?&lt;/p&gt;

&lt;p&gt;FakeItEasy has a nice fluent API that allows you to do the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[Fact]
public void Creating_Schedule_Entry_Should_Check_For_Conflicts()
{
    //Given
    var fakeScheduleRepository = A.Fake&amp;lt;IScheduleRepository&amp;gt;();
    var model = GetModel();

    var browser = new Browser(GetBootstrapper(scheduleRepository:fakeScheduleRepository));

    //When
    var result = browser.Post("/api/schedules", with =&amp;gt;
    {
        with.HttpRequest();
        with.JsonBody(model);
    });

    //Then
    A.CallTo(() =&amp;gt; fakeScheduleRepository.CheckForConflict(A&amp;lt;Schedule&amp;gt;.That.Matches(x =&amp;gt; BodyModel(x)))).MustHaveHappened();
}

private bool BodyModel(CreateKeywordSchedule match)
{
    return match.DateFrom == new DateTime(2013, 01, 01, 12, 00, 00) &amp;amp;&amp;amp;
           match.DateTo == new DateTime(2013, 01, 02, 12, 00, 00);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Spot the difference? So instead of passing our original model object in we told FakeItEasy to expect a type of Schedule that matches an an object that is of type Schedule.  We wrote a &lt;code&gt;Func&amp;lt;Schedule,bool&amp;gt;&lt;/code&gt; to determine what a match is when comparing objects.&lt;/p&gt;

&lt;p&gt;So when the test runs and &lt;code&gt;fakeScheduleRepository.CheckForConflict(model)&lt;/code&gt; is executed FakeItEasy will assert that the argument passed into &lt;code&gt;fakeScheduleRepository.CheckForConflict()&lt;/code&gt; matches the property values we decided to match on in our BodyModel method.  &lt;/p&gt;

&lt;p&gt;This way if the model we send into the route has the property values that match those we have defined in BodyModel we can pass our test.&lt;/p&gt;

&lt;p&gt;Its a much neater way without having to write &lt;code&gt;IEqualityComparer&lt;/code&gt; or anything over the top and hope you found this useful.&lt;/p&gt;
</a10:content></item></channel></rss>